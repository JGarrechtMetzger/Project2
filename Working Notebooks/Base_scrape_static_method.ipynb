{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "thick-cattle",
   "metadata": {},
   "source": [
    "# Static Method Scrape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-suggestion",
   "metadata": {},
   "source": [
    "(Not finished as of Jan 24th, 2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-catholic",
   "metadata": {},
   "source": [
    "## The \"static method\"\n",
    "\n",
    "* The first function scrapes the URLs and creates a new object for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abroad-finger",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T23:34:10.439346Z",
     "start_time": "2021-01-24T23:34:10.424904Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# -----------------------------------------------------------------\\n# Remove docstring to run code below for static method\\n\\nurl_list_results = []\\n\\nfor url in url_list:\\n    response = requests.get(url)\\n    page = response.text\\n    soup = BeautifulSoup(page, 'html.parser')\\n    results = soup.find_all('li', class_='result-row')\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    response = requests.get(url)\n",
    "        * This makes a request to the URL and returns a status code\n",
    "        \n",
    "    page = response.text\n",
    "        * the html text (str object) from the 'get(url)'\n",
    "        \n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "        * makes a BeautifulSoup object called 'page'\n",
    "        * utilizes the parser designated in quotes as the second\n",
    "            input of the method\n",
    "            \n",
    "    results = soup.find_all('li', class_='result-row')\n",
    "        * returns an element ResultSet object.\n",
    "        * this is the html text that was isolated from using the \n",
    "            'find()' or 'find_all()' methods.\n",
    "        * 'li' is an html list tag.\n",
    "        * 'class_' is the designator for a class attribute.\n",
    "            - Here this corresponds with the 'result_row' class \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "'''\n",
    "# -----------------------------------------------------------------\n",
    "# Remove docstring to run code below for static method\n",
    "\n",
    "url_list_results = []\n",
    "\n",
    "for url in url_list:\n",
    "        response = requests.get(url)\n",
    "        page = response.text\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "        results = soup.find_all('li', class_='result-row')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "minimal-disco",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T23:34:31.259385Z",
     "start_time": "2021-01-24T23:34:31.251955Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# ----------------------------------------------------------------\\n## Remove docstring to run code below for static method\\n\\n\\n\\nfor res in results:\\n    \\n        \"\"\"PRICE\"\"\"\\n        ## Loop for finding PRICE for a single page of 120 results\\n        p = res.find(\\'span\\', class_=\\'result-price\\').text\\n        price.append(p)\\n\\n        \"\"\"PICS\"\"\"\\n        ## Loop for finding the boolean HAS PICS of a single page of \\n        ## 120 results. This tests whether >=1 picture is an attribute\\n        ## of the post.\\n        if res.find(\\'span\\', class_=\\'pictag\\') is None:\\n            has_pics_bool.append(\"False\")\\n        else:\\n            has_pics_bool.append(\\'True\\')\\n\\n\\n        \"\"\"NEIGHBORHOOD\"\"\"\\n        ## Loop for finding NEIGHBORHOOD name for a single page of 120\\n        ## results.  This includes the drop down menu choices on\\n        ## Craigslist as well as the manually entered neighborhoods.\\n        if res.find(\\'span\\', class_=\"result-hood\") is None:\\n            HOOD_list.append(\"NONE\")\\n        else:    \\n            h = res.find(\\'span\\', class_=\"result-hood\").text\\n            HOOD_list.append(h)\\n\\n    \"\"\"TITLE\"\"\"    \\n    ## Loop for finding TITLE for a single page of 120 results   \\n    titles=soup.find_all(\\'a\\', class_=\"result-title hdrlnk\")\\n    for title in titles:\\n        just_titles.append(title.text) \\n\\n    \"\"\"DATETIME\"\"\"\\n    ## Loop for finding DATETIME for a single page of 120 results   \\n    posted_datetimes=soup.find_all(class_=\\'result-date\\')\\n    for posted_datetime in posted_datetimes:\\n        if posted_datetime.has_attr(\\'datetime\\'):\\n            just_posted_datetimes.append(posted_datetime[\\'datetime\\'])       \\n\\n# Compilation dictionary of for-loop results       \\ncomp_dict = {\\'price\\': price, \\n            \\'pics\\': has_pics_bool,\\n            \\'hood\\': HOOD_list,\\n            \\'title\\': just_titles,\\n            \\'datetimes\\': just_posted_datetimes}\\n\\n\\nreturn comp_dict\\n\\nprint(len(price))\\nprint(len(has_pics_bool))\\nprint(len(HOOD_list))\\nprint(len(just_titles))\\nprint(len(just_posted_datetimes))\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# ----------------------------------------------------------------\n",
    "## Remove docstring to run code below for static method\n",
    "\n",
    "\n",
    "\n",
    "for res in results:\n",
    "    \n",
    "        \"\"\"PRICE\"\"\"\n",
    "        ## Loop for finding PRICE for a single page of 120 results\n",
    "        p = res.find('span', class_='result-price').text\n",
    "        price.append(p)\n",
    "\n",
    "        \"\"\"PICS\"\"\"\n",
    "        ## Loop for finding the boolean HAS PICS of a single page of \n",
    "        ## 120 results. This tests whether >=1 picture is an attribute\n",
    "        ## of the post.\n",
    "        if res.find('span', class_='pictag') is None:\n",
    "            has_pics_bool.append(\"False\")\n",
    "        else:\n",
    "            has_pics_bool.append('True')\n",
    "\n",
    "\n",
    "        \"\"\"NEIGHBORHOOD\"\"\"\n",
    "        ## Loop for finding NEIGHBORHOOD name for a single page of 120\n",
    "        ## results.  This includes the drop down menu choices on\n",
    "        ## Craigslist as well as the manually entered neighborhoods.\n",
    "        if res.find('span', class_=\"result-hood\") is None:\n",
    "            HOOD_list.append(\"NONE\")\n",
    "        else:    \n",
    "            h = res.find('span', class_=\"result-hood\").text\n",
    "            HOOD_list.append(h)\n",
    "\n",
    "    \"\"\"TITLE\"\"\"    \n",
    "    ## Loop for finding TITLE for a single page of 120 results   \n",
    "    titles=soup.find_all('a', class_=\"result-title hdrlnk\")\n",
    "    for title in titles:\n",
    "        just_titles.append(title.text) \n",
    "\n",
    "    \"\"\"DATETIME\"\"\"\n",
    "    ## Loop for finding DATETIME for a single page of 120 results   \n",
    "    posted_datetimes=soup.find_all(class_='result-date')\n",
    "    for posted_datetime in posted_datetimes:\n",
    "        if posted_datetime.has_attr('datetime'):\n",
    "            just_posted_datetimes.append(posted_datetime['datetime'])       \n",
    "\n",
    "# Compilation dictionary of for-loop results       \n",
    "comp_dict = {'price': price, \n",
    "            'pics': has_pics_bool,\n",
    "            'hood': HOOD_list,\n",
    "            'title': just_titles,\n",
    "            'datetimes': just_posted_datetimes}\n",
    "\n",
    "\n",
    "return comp_dict\n",
    "\n",
    "print(len(price))\n",
    "print(len(has_pics_bool))\n",
    "print(len(HOOD_list))\n",
    "print(len(just_titles))\n",
    "print(len(just_posted_datetimes))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-cloud",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
